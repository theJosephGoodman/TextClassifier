{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "721035b0-1756-4ad8-8907-f0c9722ce2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "LOGREG_ROOT = './fited_logreg.sav'\n",
    "INPUT_ROOT = './input.txt'\n",
    "BERT_ROOT = './rubert-base-cased-sentence'\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import pymorphy2\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "STOPWORDS = stopwords.words('russian')\n",
    "LEMMATIZER = pymorphy2.MorphAnalyzer()\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(BERT_ROOT)\n",
    "MODEL = AutoModel.from_pretrained(BERT_ROOT)\n",
    "\n",
    "\n",
    "with open(LOGREG_ROOT, 'rb') as file:\n",
    "    logreg = pickle.load(file)\n",
    "\n",
    "with open(INPUT_ROOT, encoding='utf-8') as file:\n",
    "    lines = [line.rstrip().lstrip() for line in file]\n",
    "df = pd.DataFrame(lines, columns=['title'])\n",
    "\n",
    "def preprocess_df(df, stopwords, lemmatizer):\n",
    "    '''\n",
    "    df: датафрейм с тренировочными данными без столбца таргетов\n",
    "    stopwords: список стоп-слов\n",
    "    lemmatizer: лемматизатор от pymorphy2\n",
    "\n",
    "    функция проводит предобработку сырого текста\n",
    "    '''\n",
    "    \n",
    "    # приведение к нижнему регистру и удаление стоп-слов\n",
    "    x_filtered = df.title.str.lower().str.split(' ').apply(lambda x: [i for i in x if (i.isalpha() & ~(i in stopwords))])\n",
    "    x_filtered = x_filtered[x_filtered.apply(lambda x: len(x)>0)]\n",
    "    \n",
    "    \n",
    "    # лемматизация\n",
    "    x_lemmatized = x_filtered.apply(lambda x: [(lemmatizer.parse(word)[0]).normal_form for word in x ])\n",
    "\n",
    "    return x_lemmatized\n",
    "\n",
    "# model.cuda()  # раскоментируй, если у тебя есть GPU\n",
    "\n",
    "def embed_bert_cls(text, model, tokenizer):\n",
    "    t = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**{k: v.to(model.device) for k, v in t.items()})\n",
    "    embeddings = model_output.last_hidden_state[:, 0, :]\n",
    "    embeddings = torch.nn.functional.normalize(embeddings)\n",
    "    return embeddings[0].cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "prep_text = preprocess_df(df, STOPWORDS, LEMMATIZER).str.join(' ')\n",
    "num_words = prep_text.apply(lambda x: len(x)).values[:, np.newaxis]\n",
    "\n",
    "embeddings = [embed_bert_cls(row, MODEL, TOKENIZER) for row in prep_text]\n",
    "matrix  = np.hstack((embeddings,\n",
    "                    num_words))\n",
    "\n",
    "    \n",
    "prediction = logreg.predict(matrix)\n",
    "\n",
    "with open('output.txt', 'w') as f:\n",
    "    for item in prediction:\n",
    "        f.write(\"%s\\n\" % item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "93edbf43-563f-4db5-8dfb-8f8b5c0f5ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TerminalIPythonApp] WARNING | Subcommand `ipython nbconvert` is deprecated and will be removed in future versions.\n",
      "[TerminalIPythonApp] WARNING | You likely want to use `jupyter nbconvert` in the future\n",
      "[NbConvertApp] Converting notebook program.ipynb to script\n",
      "[NbConvertApp] Writing 2484 bytes to program.py\n"
     ]
    }
   ],
   "source": [
    "!ipython nbconvert program.ipynb --to script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8791a2-460b-497a-bdbe-f1782ad5130d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "[TerminalIPythonApp] WARNING | Subcommand `ipython nbconvert` is deprecated and will be removed in future versions.\n",
      "[TerminalIPythonApp] WARNING | You likely want to use `jupyter nbconvert` in the future\n",
      "[NbConvertApp] Converting notebook program.ipynb to script\n",
      "[NbConvertApp] Writing 2484 bytes to program.py\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator LogisticRegression from version 1.0.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "%run program.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e926ec-f894-4ce5-a198-ba7338a06fab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
